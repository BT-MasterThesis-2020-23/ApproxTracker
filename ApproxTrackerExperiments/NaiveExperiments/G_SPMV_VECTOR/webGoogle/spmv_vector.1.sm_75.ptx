







.version 7.6
.target sm_75
.address_size 64


.global .texref tex_x;











.visible .entry _Z18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_Pf(
.param .u32 _Z18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_Pf_param_0,
.param .u64 _Z18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_Pf_param_1,
.param .u64 _Z18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_Pf_param_2,
.param .u64 _Z18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_Pf_param_3,
.param .u64 _Z18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_Pf_param_4,
.param .u64 _Z18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_Pf_param_5
)
{
.reg .pred %p<10>;
.reg .f32 %f<59>;
.reg .b32 %r<48>;
.reg .b64 %rd<29>;

	.shared .align 4 .b8 _ZZ18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_PfE5sdata[1028];

	.shared .align 4 .b8 _ZZ18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_PfE4ptrs[1024];

ld.param.u32 %r22, [_Z18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_Pf_param_0];
ld.param.u64 %rd16, [_Z18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_Pf_param_1];
ld.param.u64 %rd18, [_Z18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_Pf_param_2];
ld.param.u64 %rd19, [_Z18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_Pf_param_3];
ld.param.u64 %rd17, [_Z18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_Pf_param_5];
cvta.to.global.u64 %rd1, %rd18;
cvta.to.global.u64 %rd2, %rd19;
mov.u32 %r23, %ctaid.x;
shl.b32 %r24, %r23, 8;
mov.u32 %r1, %tid.x;
and.b32 %r2, %r1, 1;
add.s32 %r25, %r24, %r1;
shr.u32 %r26, %r25, 31;
add.s32 %r27, %r25, %r26;
shr.s32 %r45, %r27, 1;
setp.ge.s32 %p1, %r45, %r22;
@%p1 bra $L__BB0_13;

cvta.to.global.u64 %rd3, %rd16;
shl.b32 %r28, %r1, 2;
and.b32 %r29, %r28, -8;
mov.u32 %r30, _ZZ18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_PfE4ptrs;
add.s32 %r5, %r30, %r29;
shl.b32 %r31, %r2, 2;
add.s32 %r4, %r5, %r31;
mov.u32 %r32, _ZZ18spmv_vector_kernelILi128ELi2EEviPKmPKiPKfS5_PfE5sdata;
add.s32 %r6, %r32, %r28;
not.b32 %r7, %r2;
add.s64 %rd5, %rd2, 16;
add.s64 %rd6, %rd1, 16;
mov.u32 %r33, %nctaid.x;
shl.b32 %r8, %r33, 7;
cvta.to.global.u64 %rd7, %rd17;
mov.f32 %f9, 0f00000000;
setp.ne.s32 %p8, %r2, 0;

$L__BB0_2:
add.s32 %r34, %r45, %r2;
mul.wide.s32 %rd20, %r34, 8;
add.s64 %rd21, %rd3, %rd20;
ld.global.u64 %rd22, [%rd21];
st.shared.u32 [%r4], %rd22;
ld.shared.u32 %r10, [%r5];
add.s32 %r11, %r10, %r2;
ld.shared.u32 %r12, [%r5+4];
setp.ge.s32 %p2, %r11, %r12;
mov.f32 %f58, %f9;
@%p2 bra $L__BB0_10;

add.s32 %r35, %r12, %r7;
sub.s32 %r13, %r35, %r10;
shr.u32 %r36, %r13, 1;
add.s32 %r37, %r36, 1;
and.b32 %r14, %r37, 3;
setp.eq.s32 %p3, %r14, 0;
mov.u32 %r46, %r11;
mov.f32 %f58, %f9;
@%p3 bra $L__BB0_7;

mul.wide.s32 %rd23, %r11, 4;
add.s64 %rd8, %rd2, %rd23;
ld.global.f32 %f12, [%rd8];
add.s64 %rd9, %rd1, %rd23;
ld.global.u32 %r38, [%rd9];
tex.1d.v4.f32.s32 {%f13, %f14, %f15, %f16}, [tex_x, {%r38}];
fma.rn.f32 %f58, %f12, %f13, 0f00000000;
add.s32 %r46, %r11, 2;
setp.eq.s32 %p4, %r14, 1;
@%p4 bra $L__BB0_7;

ld.global.f32 %f17, [%rd8+8];
ld.global.u32 %r39, [%rd9+8];
tex.1d.v4.f32.s32 {%f18, %f19, %f20, %f21}, [tex_x, {%r39}];
fma.rn.f32 %f58, %f17, %f18, %f58;
add.s32 %r46, %r11, 4;
setp.eq.s32 %p5, %r14, 2;
@%p5 bra $L__BB0_7;

ld.global.f32 %f22, [%rd8+16];
ld.global.u32 %r40, [%rd9+16];
tex.1d.v4.f32.s32 {%f23, %f24, %f25, %f26}, [tex_x, {%r40}];
fma.rn.f32 %f58, %f22, %f23, %f58;
add.s32 %r46, %r11, 6;

$L__BB0_7:
setp.lt.u32 %p6, %r13, 6;
@%p6 bra $L__BB0_10;

mul.wide.s32 %rd24, %r46, 4;
add.s64 %rd28, %rd5, %rd24;
add.s64 %rd27, %rd6, %rd24;

$L__BB0_9:
ld.global.u32 %r41, [%rd27+-16];
tex.1d.v4.f32.s32 {%f27, %f28, %f29, %f30}, [tex_x, {%r41}];
ld.global.f32 %f31, [%rd28+-16];
fma.rn.f32 %f32, %f31, %f27, %f58;
ld.global.f32 %f33, [%rd28+-8];
ld.global.u32 %r42, [%rd27+-8];
tex.1d.v4.f32.s32 {%f34, %f35, %f36, %f37}, [tex_x, {%r42}];
fma.rn.f32 %f38, %f33, %f34, %f32;
ld.global.f32 %f39, [%rd28];
ld.global.u32 %r43, [%rd27];
tex.1d.v4.f32.s32 {%f40, %f41, %f42, %f43}, [tex_x, {%r43}];
fma.rn.f32 %f44, %f39, %f40, %f38;
ld.global.f32 %f45, [%rd28+8];
ld.global.u32 %r44, [%rd27+8];
tex.1d.v4.f32.s32 {%f46, %f47, %f48, %f49}, [tex_x, {%r44}];
fma.rn.f32 %f58, %f45, %f46, %f44;
add.s64 %rd28, %rd28, 32;
add.s64 %rd27, %rd27, 32;
add.s32 %r46, %r46, 8;
setp.lt.s32 %p7, %r46, %r12;
@%p7 bra $L__BB0_9;

$L__BB0_10:
st.shared.f32 [%r6], %f58;
bar.sync 0;
bar.sync 0;
bar.sync 0;
bar.sync 0;
bar.sync 0;
ld.shared.f32 %f50, [%r6+4];
add.f32 %f51, %f58, %f50;
st.shared.f32 [%r6], %f51;
bar.sync 0;
@%p8 bra $L__BB0_12;

ld.shared.f32 %f52, [%r6];
mul.wide.s32 %rd25, %r45, 4;
add.s64 %rd26, %rd7, %rd25;
ld.global.f32 %f53, [%rd26];
add.f32 %f54, %f52, %f53;
st.global.f32 [%rd26], %f54;

$L__BB0_12:
add.s32 %r45, %r45, %r8;
setp.lt.s32 %p9, %r45, %r22;
@%p9 bra $L__BB0_2;

$L__BB0_13:
ret;

}

.visible .entry _Z18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_Pf(
.param .u32 _Z18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_Pf_param_0,
.param .u64 _Z18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_Pf_param_1,
.param .u64 _Z18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_Pf_param_2,
.param .u64 _Z18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_Pf_param_3,
.param .u64 _Z18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_Pf_param_4,
.param .u64 _Z18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_Pf_param_5
)
{
.reg .pred %p<11>;
.reg .f32 %f<61>;
.reg .b32 %r<50>;
.reg .b64 %rd<29>;

	.shared .align 4 .b8 _ZZ18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_PfE5sdata[1032];

	.shared .align 4 .b8 _ZZ18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_PfE4ptrs[512];

ld.param.u32 %r22, [_Z18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_Pf_param_0];
ld.param.u64 %rd16, [_Z18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_Pf_param_1];
ld.param.u64 %rd18, [_Z18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_Pf_param_2];
ld.param.u64 %rd19, [_Z18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_Pf_param_3];
ld.param.u64 %rd17, [_Z18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_Pf_param_5];
cvta.to.global.u64 %rd1, %rd18;
cvta.to.global.u64 %rd2, %rd19;
mov.u32 %r23, %ctaid.x;
shl.b32 %r24, %r23, 8;
mov.u32 %r1, %tid.x;
add.s32 %r25, %r24, %r1;
and.b32 %r2, %r1, 3;
shr.s32 %r26, %r25, 31;
shr.u32 %r27, %r26, 30;
add.s32 %r28, %r25, %r27;
shr.s32 %r47, %r28, 2;
setp.ge.s32 %p1, %r47, %r22;
@%p1 bra $L__BB1_15;

cvta.to.global.u64 %rd3, %rd16;
shl.b32 %r29, %r1, 1;
and.b32 %r30, %r29, -8;
mov.u32 %r31, _ZZ18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_PfE4ptrs;
add.s32 %r5, %r31, %r30;
shl.b32 %r32, %r2, 2;
add.s32 %r4, %r5, %r32;
shl.b32 %r33, %r1, 2;
mov.u32 %r34, _ZZ18spmv_vector_kernelILi64ELi4EEviPKmPKiPKfS5_PfE5sdata;
add.s32 %r6, %r34, %r33;
not.b32 %r7, %r2;
add.s64 %rd5, %rd2, 32;
add.s64 %rd6, %rd1, 32;
mov.u32 %r35, %nctaid.x;
shl.b32 %r8, %r35, 6;
cvta.to.global.u64 %rd7, %rd17;
setp.gt.u32 %p2, %r2, 1;
mov.f32 %f9, 0f00000000;
setp.ne.s32 %p9, %r2, 0;

$L__BB1_2:
@%p2 bra $L__BB1_4;

add.s32 %r36, %r47, %r2;
mul.wide.s32 %rd20, %r36, 8;
add.s64 %rd21, %rd3, %rd20;
ld.global.u64 %rd22, [%rd21];
st.shared.u32 [%r4], %rd22;

$L__BB1_4:
ld.shared.u32 %r10, [%r5];
add.s32 %r11, %r10, %r2;
ld.shared.u32 %r12, [%r5+4];
setp.ge.s32 %p3, %r11, %r12;
mov.f32 %f60, %f9;
@%p3 bra $L__BB1_12;

add.s32 %r37, %r12, %r7;
sub.s32 %r13, %r37, %r10;
shr.u32 %r38, %r13, 2;
add.s32 %r39, %r38, 1;
and.b32 %r14, %r39, 3;
setp.eq.s32 %p4, %r14, 0;
mov.u32 %r48, %r11;
mov.f32 %f60, %f9;
@%p4 bra $L__BB1_9;

mul.wide.s32 %rd23, %r11, 4;
add.s64 %rd8, %rd2, %rd23;
ld.global.f32 %f12, [%rd8];
add.s64 %rd9, %rd1, %rd23;
ld.global.u32 %r40, [%rd9];
tex.1d.v4.f32.s32 {%f13, %f14, %f15, %f16}, [tex_x, {%r40}];
fma.rn.f32 %f60, %f12, %f13, 0f00000000;
add.s32 %r48, %r11, 4;
setp.eq.s32 %p5, %r14, 1;
@%p5 bra $L__BB1_9;

ld.global.f32 %f17, [%rd8+16];
ld.global.u32 %r41, [%rd9+16];
tex.1d.v4.f32.s32 {%f18, %f19, %f20, %f21}, [tex_x, {%r41}];
fma.rn.f32 %f60, %f17, %f18, %f60;
add.s32 %r48, %r11, 8;
setp.eq.s32 %p6, %r14, 2;
@%p6 bra $L__BB1_9;

ld.global.f32 %f22, [%rd8+32];
ld.global.u32 %r42, [%rd9+32];
tex.1d.v4.f32.s32 {%f23, %f24, %f25, %f26}, [tex_x, {%r42}];
fma.rn.f32 %f60, %f22, %f23, %f60;
add.s32 %r48, %r11, 12;

$L__BB1_9:
setp.lt.u32 %p7, %r13, 12;
@%p7 bra $L__BB1_12;

mul.wide.s32 %rd24, %r48, 4;
add.s64 %rd28, %rd5, %rd24;
add.s64 %rd27, %rd6, %rd24;

$L__BB1_11:
ld.global.u32 %r43, [%rd27+-32];
tex.1d.v4.f32.s32 {%f27, %f28, %f29, %f30}, [tex_x, {%r43}];
ld.global.f32 %f31, [%rd28+-32];
fma.rn.f32 %f32, %f31, %f27, %f60;
ld.global.f32 %f33, [%rd28+-16];
ld.global.u32 %r44, [%rd27+-16];
tex.1d.v4.f32.s32 {%f34, %f35, %f36, %f37}, [tex_x, {%r44}];
fma.rn.f32 %f38, %f33, %f34, %f32;
ld.global.f32 %f39, [%rd28];
ld.global.u32 %r45, [%rd27];
tex.1d.v4.f32.s32 {%f40, %f41, %f42, %f43}, [tex_x, {%r45}];
fma.rn.f32 %f44, %f39, %f40, %f38;
ld.global.f32 %f45, [%rd28+16];
ld.global.u32 %r46, [%rd27+16];
tex.1d.v4.f32.s32 {%f46, %f47, %f48, %f49}, [tex_x, {%r46}];
fma.rn.f32 %f60, %f45, %f46, %f44;
add.s64 %rd28, %rd28, 64;
add.s64 %rd27, %rd27, 64;
add.s32 %r48, %r48, 16;
setp.lt.s32 %p8, %r48, %r12;
@%p8 bra $L__BB1_11;

$L__BB1_12:
st.shared.f32 [%r6], %f60;
bar.sync 0;
bar.sync 0;
bar.sync 0;
bar.sync 0;
ld.shared.f32 %f50, [%r6+8];
add.f32 %f51, %f60, %f50;
st.shared.f32 [%r6], %f51;
bar.sync 0;
ld.shared.f32 %f52, [%r6+4];
add.f32 %f53, %f51, %f52;
st.shared.f32 [%r6], %f53;
bar.sync 0;
@%p9 bra $L__BB1_14;

ld.shared.f32 %f54, [%r6];
mul.wide.s32 %rd25, %r47, 4;
add.s64 %rd26, %rd7, %rd25;
ld.global.f32 %f55, [%rd26];
add.f32 %f56, %f54, %f55;
st.global.f32 [%rd26], %f56;

$L__BB1_14:
add.s32 %r47, %r47, %r8;
setp.lt.s32 %p10, %r47, %r22;
@%p10 bra $L__BB1_2;

$L__BB1_15:
ret;

}

.visible .entry _Z18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_Pf(
.param .u32 _Z18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_Pf_param_0,
.param .u64 _Z18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_Pf_param_1,
.param .u64 _Z18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_Pf_param_2,
.param .u64 _Z18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_Pf_param_3,
.param .u64 _Z18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_Pf_param_4,
.param .u64 _Z18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_Pf_param_5
)
{
.reg .pred %p<11>;
.reg .f32 %f<63>;
.reg .b32 %r<49>;
.reg .b64 %rd<29>;

	.shared .align 4 .b8 _ZZ18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_PfE5sdata[1040];

	.shared .align 4 .b8 _ZZ18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_PfE4ptrs[256];

ld.param.u32 %r22, [_Z18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_Pf_param_0];
ld.param.u64 %rd16, [_Z18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_Pf_param_1];
ld.param.u64 %rd18, [_Z18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_Pf_param_2];
ld.param.u64 %rd19, [_Z18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_Pf_param_3];
ld.param.u64 %rd17, [_Z18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_Pf_param_5];
cvta.to.global.u64 %rd1, %rd18;
cvta.to.global.u64 %rd2, %rd19;
mov.u32 %r23, %ctaid.x;
shl.b32 %r24, %r23, 8;
mov.u32 %r1, %tid.x;
add.s32 %r25, %r24, %r1;
and.b32 %r2, %r1, 7;
shr.s32 %r26, %r25, 31;
shr.u32 %r27, %r26, 29;
add.s32 %r28, %r25, %r27;
shr.s32 %r46, %r28, 3;
setp.ge.s32 %p1, %r46, %r22;
@%p1 bra $L__BB2_15;

cvta.to.global.u64 %rd3, %rd16;
and.b32 %r29, %r1, -8;
mov.u32 %r30, _ZZ18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_PfE4ptrs;
add.s32 %r5, %r30, %r29;
shl.b32 %r31, %r2, 2;
add.s32 %r4, %r5, %r31;
shl.b32 %r32, %r1, 2;
mov.u32 %r33, _ZZ18spmv_vector_kernelILi32ELi8EEviPKmPKiPKfS5_PfE5sdata;
add.s32 %r6, %r33, %r32;
not.b32 %r7, %r2;
add.s64 %rd5, %rd2, 64;
add.s64 %rd6, %rd1, 64;
mov.u32 %r34, %nctaid.x;
shl.b32 %r8, %r34, 5;
cvta.to.global.u64 %rd7, %rd17;
setp.gt.u32 %p2, %r2, 1;
mov.f32 %f9, 0f00000000;
setp.ne.s32 %p9, %r2, 0;

$L__BB2_2:
@%p2 bra $L__BB2_4;

add.s32 %r35, %r46, %r2;
mul.wide.s32 %rd20, %r35, 8;
add.s64 %rd21, %rd3, %rd20;
ld.global.u64 %rd22, [%rd21];
st.shared.u32 [%r4], %rd22;

$L__BB2_4:
ld.shared.u32 %r10, [%r5];
add.s32 %r11, %r10, %r2;
ld.shared.u32 %r12, [%r5+4];
setp.ge.s32 %p3, %r11, %r12;
mov.f32 %f62, %f9;
@%p3 bra $L__BB2_12;

add.s32 %r36, %r12, %r7;
sub.s32 %r13, %r36, %r10;
shr.u32 %r37, %r13, 3;
add.s32 %r38, %r37, 1;
and.b32 %r14, %r38, 3;
setp.eq.s32 %p4, %r14, 0;
mov.u32 %r47, %r11;
mov.f32 %f62, %f9;
@%p4 bra $L__BB2_9;

mul.wide.s32 %rd23, %r11, 4;
add.s64 %rd8, %rd2, %rd23;
ld.global.f32 %f12, [%rd8];
add.s64 %rd9, %rd1, %rd23;
ld.global.u32 %r39, [%rd9];
tex.1d.v4.f32.s32 {%f13, %f14, %f15, %f16}, [tex_x, {%r39}];
fma.rn.f32 %f62, %f12, %f13, 0f00000000;
add.s32 %r47, %r11, 8;
setp.eq.s32 %p5, %r14, 1;
@%p5 bra $L__BB2_9;

ld.global.f32 %f17, [%rd8+32];
ld.global.u32 %r40, [%rd9+32];
tex.1d.v4.f32.s32 {%f18, %f19, %f20, %f21}, [tex_x, {%r40}];
fma.rn.f32 %f62, %f17, %f18, %f62;
add.s32 %r47, %r11, 16;
setp.eq.s32 %p6, %r14, 2;
@%p6 bra $L__BB2_9;

ld.global.f32 %f22, [%rd8+64];
ld.global.u32 %r41, [%rd9+64];
tex.1d.v4.f32.s32 {%f23, %f24, %f25, %f26}, [tex_x, {%r41}];
fma.rn.f32 %f62, %f22, %f23, %f62;
add.s32 %r47, %r11, 24;

$L__BB2_9:
setp.lt.u32 %p7, %r13, 24;
@%p7 bra $L__BB2_12;

mul.wide.s32 %rd24, %r47, 4;
add.s64 %rd28, %rd5, %rd24;
add.s64 %rd27, %rd6, %rd24;

$L__BB2_11:
ld.global.u32 %r42, [%rd27+-64];
tex.1d.v4.f32.s32 {%f27, %f28, %f29, %f30}, [tex_x, {%r42}];
ld.global.f32 %f31, [%rd28+-64];
fma.rn.f32 %f32, %f31, %f27, %f62;
ld.global.f32 %f33, [%rd28+-32];
ld.global.u32 %r43, [%rd27+-32];
tex.1d.v4.f32.s32 {%f34, %f35, %f36, %f37}, [tex_x, {%r43}];
fma.rn.f32 %f38, %f33, %f34, %f32;
ld.global.f32 %f39, [%rd28];
ld.global.u32 %r44, [%rd27];
tex.1d.v4.f32.s32 {%f40, %f41, %f42, %f43}, [tex_x, {%r44}];
fma.rn.f32 %f44, %f39, %f40, %f38;
ld.global.f32 %f45, [%rd28+32];
ld.global.u32 %r45, [%rd27+32];
tex.1d.v4.f32.s32 {%f46, %f47, %f48, %f49}, [tex_x, {%r45}];
fma.rn.f32 %f62, %f45, %f46, %f44;
add.s64 %rd28, %rd28, 128;
add.s64 %rd27, %rd27, 128;
add.s32 %r47, %r47, 32;
setp.lt.s32 %p8, %r47, %r12;
@%p8 bra $L__BB2_11;

$L__BB2_12:
st.shared.f32 [%r6], %f62;
bar.sync 0;
bar.sync 0;
bar.sync 0;
ld.shared.f32 %f50, [%r6+16];
add.f32 %f51, %f62, %f50;
st.shared.f32 [%r6], %f51;
bar.sync 0;
ld.shared.f32 %f52, [%r6+8];
add.f32 %f53, %f51, %f52;
st.shared.f32 [%r6], %f53;
bar.sync 0;
ld.shared.f32 %f54, [%r6+4];
add.f32 %f55, %f53, %f54;
st.shared.f32 [%r6], %f55;
bar.sync 0;
@%p9 bra $L__BB2_14;

ld.shared.f32 %f56, [%r6];
mul.wide.s32 %rd25, %r46, 4;
add.s64 %rd26, %rd7, %rd25;
ld.global.f32 %f57, [%rd26];
add.f32 %f58, %f56, %f57;
st.global.f32 [%rd26], %f58;

$L__BB2_14:
add.s32 %r46, %r46, %r8;
setp.lt.s32 %p10, %r46, %r22;
@%p10 bra $L__BB2_2;

$L__BB2_15:
ret;

}

.visible .entry _Z18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_Pf(
.param .u32 _Z18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_Pf_param_0,
.param .u64 _Z18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_Pf_param_1,
.param .u64 _Z18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_Pf_param_2,
.param .u64 _Z18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_Pf_param_3,
.param .u64 _Z18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_Pf_param_4,
.param .u64 _Z18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_Pf_param_5
)
{
.reg .pred %p<11>;
.reg .f32 %f<65>;
.reg .b32 %r<50>;
.reg .b64 %rd<29>;

	.shared .align 4 .b8 _ZZ18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_PfE5sdata[1056];

	.shared .align 4 .b8 _ZZ18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_PfE4ptrs[128];

ld.param.u32 %r22, [_Z18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_Pf_param_0];
ld.param.u64 %rd16, [_Z18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_Pf_param_1];
ld.param.u64 %rd18, [_Z18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_Pf_param_2];
ld.param.u64 %rd19, [_Z18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_Pf_param_3];
ld.param.u64 %rd17, [_Z18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_Pf_param_5];
cvta.to.global.u64 %rd1, %rd18;
cvta.to.global.u64 %rd2, %rd19;
mov.u32 %r23, %ctaid.x;
shl.b32 %r24, %r23, 8;
mov.u32 %r1, %tid.x;
add.s32 %r25, %r24, %r1;
and.b32 %r2, %r1, 15;
shr.s32 %r26, %r25, 31;
shr.u32 %r27, %r26, 28;
add.s32 %r28, %r25, %r27;
shr.s32 %r47, %r28, 4;
setp.ge.s32 %p1, %r47, %r22;
@%p1 bra $L__BB3_15;

cvta.to.global.u64 %rd3, %rd16;
shr.u32 %r29, %r1, 1;
and.b32 %r30, %r29, 2147483640;
mov.u32 %r31, _ZZ18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_PfE4ptrs;
add.s32 %r5, %r31, %r30;
shl.b32 %r32, %r2, 2;
add.s32 %r4, %r5, %r32;
shl.b32 %r33, %r1, 2;
mov.u32 %r34, _ZZ18spmv_vector_kernelILi16ELi16EEviPKmPKiPKfS5_PfE5sdata;
add.s32 %r6, %r34, %r33;
not.b32 %r7, %r2;
add.s64 %rd5, %rd2, 128;
add.s64 %rd6, %rd1, 128;
mov.u32 %r35, %nctaid.x;
shl.b32 %r8, %r35, 4;
cvta.to.global.u64 %rd7, %rd17;
setp.gt.u32 %p2, %r2, 1;
mov.f32 %f9, 0f00000000;
setp.ne.s32 %p9, %r2, 0;

$L__BB3_2:
@%p2 bra $L__BB3_4;

add.s32 %r36, %r47, %r2;
mul.wide.s32 %rd20, %r36, 8;
add.s64 %rd21, %rd3, %rd20;
ld.global.u64 %rd22, [%rd21];
st.shared.u32 [%r4], %rd22;

$L__BB3_4:
ld.shared.u32 %r10, [%r5];
add.s32 %r11, %r10, %r2;
ld.shared.u32 %r12, [%r5+4];
setp.ge.s32 %p3, %r11, %r12;
mov.f32 %f64, %f9;
@%p3 bra $L__BB3_12;

add.s32 %r37, %r12, %r7;
sub.s32 %r13, %r37, %r10;
shr.u32 %r38, %r13, 4;
add.s32 %r39, %r38, 1;
and.b32 %r14, %r39, 3;
setp.eq.s32 %p4, %r14, 0;
mov.u32 %r48, %r11;
mov.f32 %f64, %f9;
@%p4 bra $L__BB3_9;

mul.wide.s32 %rd23, %r11, 4;
add.s64 %rd8, %rd2, %rd23;
ld.global.f32 %f12, [%rd8];
add.s64 %rd9, %rd1, %rd23;
ld.global.u32 %r40, [%rd9];
tex.1d.v4.f32.s32 {%f13, %f14, %f15, %f16}, [tex_x, {%r40}];
fma.rn.f32 %f64, %f12, %f13, 0f00000000;
add.s32 %r48, %r11, 16;
setp.eq.s32 %p5, %r14, 1;
@%p5 bra $L__BB3_9;

ld.global.f32 %f17, [%rd8+64];
ld.global.u32 %r41, [%rd9+64];
tex.1d.v4.f32.s32 {%f18, %f19, %f20, %f21}, [tex_x, {%r41}];
fma.rn.f32 %f64, %f17, %f18, %f64;
add.s32 %r48, %r11, 32;
setp.eq.s32 %p6, %r14, 2;
@%p6 bra $L__BB3_9;

ld.global.f32 %f22, [%rd8+128];
ld.global.u32 %r42, [%rd9+128];
tex.1d.v4.f32.s32 {%f23, %f24, %f25, %f26}, [tex_x, {%r42}];
fma.rn.f32 %f64, %f22, %f23, %f64;
add.s32 %r48, %r11, 48;

$L__BB3_9:
setp.lt.u32 %p7, %r13, 48;
@%p7 bra $L__BB3_12;

mul.wide.s32 %rd24, %r48, 4;
add.s64 %rd28, %rd5, %rd24;
add.s64 %rd27, %rd6, %rd24;

$L__BB3_11:
ld.global.u32 %r43, [%rd27+-128];
tex.1d.v4.f32.s32 {%f27, %f28, %f29, %f30}, [tex_x, {%r43}];
ld.global.f32 %f31, [%rd28+-128];
fma.rn.f32 %f32, %f31, %f27, %f64;
ld.global.f32 %f33, [%rd28+-64];
ld.global.u32 %r44, [%rd27+-64];
tex.1d.v4.f32.s32 {%f34, %f35, %f36, %f37}, [tex_x, {%r44}];
fma.rn.f32 %f38, %f33, %f34, %f32;
ld.global.f32 %f39, [%rd28];
ld.global.u32 %r45, [%rd27];
tex.1d.v4.f32.s32 {%f40, %f41, %f42, %f43}, [tex_x, {%r45}];
fma.rn.f32 %f44, %f39, %f40, %f38;
ld.global.f32 %f45, [%rd28+64];
ld.global.u32 %r46, [%rd27+64];
tex.1d.v4.f32.s32 {%f46, %f47, %f48, %f49}, [tex_x, {%r46}];
fma.rn.f32 %f64, %f45, %f46, %f44;
add.s64 %rd28, %rd28, 256;
add.s64 %rd27, %rd27, 256;
add.s32 %r48, %r48, 64;
setp.lt.s32 %p8, %r48, %r12;
@%p8 bra $L__BB3_11;

$L__BB3_12:
st.shared.f32 [%r6], %f64;
bar.sync 0;
bar.sync 0;
ld.shared.f32 %f50, [%r6+32];
add.f32 %f51, %f64, %f50;
st.shared.f32 [%r6], %f51;
bar.sync 0;
ld.shared.f32 %f52, [%r6+16];
add.f32 %f53, %f51, %f52;
st.shared.f32 [%r6], %f53;
bar.sync 0;
ld.shared.f32 %f54, [%r6+8];
add.f32 %f55, %f53, %f54;
st.shared.f32 [%r6], %f55;
bar.sync 0;
ld.shared.f32 %f56, [%r6+4];
add.f32 %f57, %f55, %f56;
st.shared.f32 [%r6], %f57;
bar.sync 0;
@%p9 bra $L__BB3_14;

ld.shared.f32 %f58, [%r6];
mul.wide.s32 %rd25, %r47, 4;
add.s64 %rd26, %rd7, %rd25;
ld.global.f32 %f59, [%rd26];
add.f32 %f60, %f58, %f59;
st.global.f32 [%rd26], %f60;

$L__BB3_14:
add.s32 %r47, %r47, %r8;
setp.lt.s32 %p10, %r47, %r22;
@%p10 bra $L__BB3_2;

$L__BB3_15:
ret;

}

.visible .entry _Z18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_Pf(
.param .u32 _Z18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_Pf_param_0,
.param .u64 _Z18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_Pf_param_1,
.param .u64 _Z18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_Pf_param_2,
.param .u64 _Z18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_Pf_param_3,
.param .u64 _Z18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_Pf_param_4,
.param .u64 _Z18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_Pf_param_5
)
{
.reg .pred %p<11>;
.reg .f32 %f<67>;
.reg .b32 %r<50>;
.reg .b64 %rd<29>;

	.shared .align 4 .b8 _ZZ18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_PfE5sdata[1088];

	.shared .align 4 .b8 _ZZ18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_PfE4ptrs[64];

ld.param.u32 %r22, [_Z18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_Pf_param_0];
ld.param.u64 %rd16, [_Z18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_Pf_param_1];
ld.param.u64 %rd18, [_Z18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_Pf_param_2];
ld.param.u64 %rd19, [_Z18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_Pf_param_3];
ld.param.u64 %rd17, [_Z18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_Pf_param_5];
cvta.to.global.u64 %rd1, %rd18;
cvta.to.global.u64 %rd2, %rd19;
mov.u32 %r23, %ctaid.x;
shl.b32 %r24, %r23, 8;
mov.u32 %r1, %tid.x;
add.s32 %r25, %r24, %r1;
and.b32 %r2, %r1, 31;
shr.s32 %r26, %r25, 31;
shr.u32 %r27, %r26, 27;
add.s32 %r28, %r25, %r27;
shr.s32 %r47, %r28, 5;
setp.ge.s32 %p1, %r47, %r22;
@%p1 bra $L__BB4_15;

cvta.to.global.u64 %rd3, %rd16;
shr.u32 %r29, %r1, 2;
and.b32 %r30, %r29, 1073741816;
mov.u32 %r31, _ZZ18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_PfE4ptrs;
add.s32 %r5, %r31, %r30;
shl.b32 %r32, %r2, 2;
add.s32 %r4, %r5, %r32;
shl.b32 %r33, %r1, 2;
mov.u32 %r34, _ZZ18spmv_vector_kernelILi8ELi32EEviPKmPKiPKfS5_PfE5sdata;
add.s32 %r6, %r34, %r33;
not.b32 %r7, %r2;
add.s64 %rd5, %rd2, 256;
add.s64 %rd6, %rd1, 256;
mov.u32 %r35, %nctaid.x;
shl.b32 %r8, %r35, 3;
cvta.to.global.u64 %rd7, %rd17;
setp.gt.u32 %p2, %r2, 1;
mov.f32 %f9, 0f00000000;
setp.ne.s32 %p9, %r2, 0;

$L__BB4_2:
@%p2 bra $L__BB4_4;

add.s32 %r36, %r47, %r2;
mul.wide.s32 %rd20, %r36, 8;
add.s64 %rd21, %rd3, %rd20;
ld.global.u64 %rd22, [%rd21];
st.shared.u32 [%r4], %rd22;

$L__BB4_4:
ld.shared.u32 %r10, [%r5];
add.s32 %r11, %r10, %r2;
ld.shared.u32 %r12, [%r5+4];
setp.ge.s32 %p3, %r11, %r12;
mov.f32 %f66, %f9;
@%p3 bra $L__BB4_12;

add.s32 %r37, %r12, %r7;
sub.s32 %r13, %r37, %r10;
shr.u32 %r38, %r13, 5;
add.s32 %r39, %r38, 1;
and.b32 %r14, %r39, 3;
setp.eq.s32 %p4, %r14, 0;
mov.u32 %r48, %r11;
mov.f32 %f66, %f9;
@%p4 bra $L__BB4_9;

mul.wide.s32 %rd23, %r11, 4;
add.s64 %rd8, %rd2, %rd23;
ld.global.f32 %f12, [%rd8];
add.s64 %rd9, %rd1, %rd23;
ld.global.u32 %r40, [%rd9];
tex.1d.v4.f32.s32 {%f13, %f14, %f15, %f16}, [tex_x, {%r40}];
fma.rn.f32 %f66, %f12, %f13, 0f00000000;
add.s32 %r48, %r11, 32;
setp.eq.s32 %p5, %r14, 1;
@%p5 bra $L__BB4_9;

ld.global.f32 %f17, [%rd8+128];
ld.global.u32 %r41, [%rd9+128];
tex.1d.v4.f32.s32 {%f18, %f19, %f20, %f21}, [tex_x, {%r41}];
fma.rn.f32 %f66, %f17, %f18, %f66;
add.s32 %r48, %r11, 64;
setp.eq.s32 %p6, %r14, 2;
@%p6 bra $L__BB4_9;

ld.global.f32 %f22, [%rd8+256];
ld.global.u32 %r42, [%rd9+256];
tex.1d.v4.f32.s32 {%f23, %f24, %f25, %f26}, [tex_x, {%r42}];
fma.rn.f32 %f66, %f22, %f23, %f66;
add.s32 %r48, %r11, 96;

$L__BB4_9:
setp.lt.u32 %p7, %r13, 96;
@%p7 bra $L__BB4_12;

mul.wide.s32 %rd24, %r48, 4;
add.s64 %rd28, %rd5, %rd24;
add.s64 %rd27, %rd6, %rd24;

$L__BB4_11:
ld.global.u32 %r43, [%rd27+-256];
tex.1d.v4.f32.s32 {%f27, %f28, %f29, %f30}, [tex_x, {%r43}];
ld.global.f32 %f31, [%rd28+-256];
fma.rn.f32 %f32, %f31, %f27, %f66;
ld.global.f32 %f33, [%rd28+-128];
ld.global.u32 %r44, [%rd27+-128];
tex.1d.v4.f32.s32 {%f34, %f35, %f36, %f37}, [tex_x, {%r44}];
fma.rn.f32 %f38, %f33, %f34, %f32;
ld.global.f32 %f39, [%rd28];
ld.global.u32 %r45, [%rd27];
tex.1d.v4.f32.s32 {%f40, %f41, %f42, %f43}, [tex_x, {%r45}];
fma.rn.f32 %f44, %f39, %f40, %f38;
ld.global.f32 %f45, [%rd28+128];
ld.global.u32 %r46, [%rd27+128];
tex.1d.v4.f32.s32 {%f46, %f47, %f48, %f49}, [tex_x, {%r46}];
fma.rn.f32 %f66, %f45, %f46, %f44;
add.s64 %rd28, %rd28, 512;
add.s64 %rd27, %rd27, 512;
add.s32 %r48, %r48, 128;
setp.lt.s32 %p8, %r48, %r12;
@%p8 bra $L__BB4_11;

$L__BB4_12:
st.shared.f32 [%r6], %f66;
bar.sync 0;
ld.shared.f32 %f50, [%r6+64];
add.f32 %f51, %f66, %f50;
st.shared.f32 [%r6], %f51;
bar.sync 0;
ld.shared.f32 %f52, [%r6+32];
add.f32 %f53, %f51, %f52;
st.shared.f32 [%r6], %f53;
bar.sync 0;
ld.shared.f32 %f54, [%r6+16];
add.f32 %f55, %f53, %f54;
st.shared.f32 [%r6], %f55;
bar.sync 0;
ld.shared.f32 %f56, [%r6+8];
add.f32 %f57, %f55, %f56;
st.shared.f32 [%r6], %f57;
bar.sync 0;
ld.shared.f32 %f58, [%r6+4];
add.f32 %f59, %f57, %f58;
st.shared.f32 [%r6], %f59;
bar.sync 0;
@%p9 bra $L__BB4_14;

ld.shared.f32 %f60, [%r6];
mul.wide.s32 %rd25, %r47, 4;
add.s64 %rd26, %rd7, %rd25;
ld.global.f32 %f61, [%rd26];
add.f32 %f62, %f60, %f61;
st.global.f32 [%rd26], %f62;

$L__BB4_14:
add.s32 %r47, %r47, %r8;
setp.lt.s32 %p10, %r47, %r22;
@%p10 bra $L__BB4_2;

$L__BB4_15:
ret;

}

